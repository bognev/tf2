{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 DeepMind Technologies Limited and Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Training script.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "import numpy as np\n",
    "\n",
    "import sonnet as snt\n",
    "# import tensorflow.compat.v1 as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import logging as log\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(log.INFO)\n",
    "\n",
    "import cs\n",
    "import file_utils\n",
    "import utils\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'mode', 'recons', 'Model mode.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_training_iterations', 10000000,\n",
    "    'Number of training iterations.')\n",
    "flags.DEFINE_integer(\n",
    "    'batch_size', 64, 'Training batch size.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_measurements', 25, 'The number of measurements')\n",
    "flags.DEFINE_integer(\n",
    "    'num_latents', 100, 'The number of latents')\n",
    "flags.DEFINE_integer(\n",
    "    'num_z_iters', 3, 'The number of latent optimisation steps.')\n",
    "flags.DEFINE_float(\n",
    "    'z_step_size', 0.01, 'Step size for latent optimisation.')\n",
    "flags.DEFINE_string(\n",
    "    'z_project_method', 'norm', 'The method to project z.')\n",
    "flags.DEFINE_integer(\n",
    "    'summary_every_step', 10,\n",
    "    'The interval at which to log debug ops.')\n",
    "flags.DEFINE_integer(\n",
    "    'export_every', 10,\n",
    "    'The interval at which to export samples.')\n",
    "flags.DEFINE_string(\n",
    "    'dataset', 'mnist', 'The dataset used for learning (cifar|mnist.')\n",
    "flags.DEFINE_float('learning_rate', 1e-4, 'Learning rate.')\n",
    "flags.DEFINE_string(\n",
    "    'output_dir', '/tmp/cs_gan/cs', 'Location where to save output files.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "logging.info(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "logging.info(\"    Sonnet version: {}\".format(snt.__version__))\n",
    "logging.info(\"    Numpy  version: {}\".format(np.__version__))\n",
    "\n",
    "output_dir = os.path.join(FLAGS.output_dir, 'summaries')\n",
    "os.system('rm -rf '+output_dir)\n",
    "\n",
    "utils.make_output_dir(FLAGS.output_dir)\n",
    "data_processor = utils.DataProcessor()\n",
    "images = utils.get_train_dataset(data_processor, FLAGS.dataset,\n",
    "                                     FLAGS.batch_size)\n",
    "\n",
    "logging.info('Learning rate: %d', FLAGS.learning_rate)\n",
    "\n",
    "\n",
    "    # Construct optimizers.\n",
    "optimizer = snt.optimizers.Adam(FLAGS.learning_rate)\n",
    "\n",
    "    # Create the networks and models.\n",
    "generator = utils.get_generator(FLAGS.dataset)\n",
    "metric_net = utils.get_metric_net(FLAGS.dataset, FLAGS.num_measurements)\n",
    "model = cs.CS(metric_net, generator,\n",
    "                FLAGS.num_z_iters, FLAGS.z_step_size, FLAGS.z_project_method, optimizer)\n",
    "\n",
    "sample_exporter = file_utils.FileExporter(\n",
    "        os.path.join(FLAGS.output_dir, 'reconstructions'))\n",
    "\n",
    "writer = tf.summary.create_file_writer(output_dir)\n",
    "logging.info('starting training')\n",
    "for num_epochs in range(FLAGS.num_training_iterations):\n",
    "    images = utils.get_train_dataset(data_processor, FLAGS.dataset,\n",
    "                                        FLAGS.batch_size)\n",
    "    for i, batch in enumerate(images):\n",
    "        prior = utils.make_prior(FLAGS.num_latents)\n",
    "        generator_inputs = prior.sample(FLAGS.batch_size)\n",
    "        model_output = model.step(batch, generator_inputs)\n",
    "        debug_ops = model_output.debug_ops\n",
    "        reconstructions, _ = utils.optimise_and_sample(generator_inputs, model, batch, is_training=False)\n",
    "        debug_ops['it'] = i\n",
    "        if i % FLAGS.summary_every_step == 0:\n",
    "            with writer.as_default():\n",
    "                for name, op in debug_ops.items():\n",
    "                    tf.summary.scalar(name, op, debug_ops['it'])\n",
    "\n",
    "        # if num_epochs % FLAGS.export_every == 0:\n",
    "        #     reconstructions_np, data_np = sess.run([reconstructions, images])\n",
    "        #     # Create an object which gets data and does the processing.\n",
    "        #     data_np = data_processor.postprocess(data_np)\n",
    "        #     reconstructions_np = data_processor.postprocess(reconstructions_np)\n",
    "        #     sample_exporter.save(reconstructions_np, 'reconstructions')\n",
    "        #     sample_exporter.save(data_np, 'data')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
