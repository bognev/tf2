{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(-20,30,2)[np.arange(14,14+3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class HDF5Store(object):\n",
    "    \"\"\"\n",
    "    Simple class to append value to a hdf5 file on disc (usefull for building keras datasets)\n",
    "    \n",
    "    Params:\n",
    "        datapath: filepath of h5 file\n",
    "        dataset: dataset name within the file\n",
    "        shape: dataset shape (not counting main/batch axis)\n",
    "        dtype: numpy dtype\n",
    "    \n",
    "    Usage:\n",
    "        hdf5_store = HDF5Store('/tmp/hdf5_store.h5','X', shape=(20,20,3))\n",
    "        x = np.random.random(hdf5_store.shape)\n",
    "        hdf5_store.append(x)\n",
    "        hdf5_store.append(x)\n",
    "        \n",
    "    From https://gist.github.com/wassname/a0a75f133831eed1113d052c67cf8633\n",
    "    \"\"\"\n",
    "    def __init__(self, datapath, dataset, shape, dtype=np.float32, compression=\"gzip\", chunk_len=1):\n",
    "        self.datapath = datapath\n",
    "        self.dataset = dataset\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "        print(self.dataset)\n",
    "        self.id = [0]*len(self.dataset)\n",
    "        \n",
    "        with h5py.File(self.datapath, mode='w') as h5f:\n",
    "            for i in range(len(self.dataset)):\n",
    "                self.dset = h5f.create_dataset(\n",
    "                    self.dataset[i],\n",
    "                    shape=(0, ) + self.shape[i],\n",
    "                    maxshape=(None, ) + self.shape[i],\n",
    "                    dtype=self.dtype[i],\n",
    "                    compression=compression,\n",
    "                    chunks=(chunk_len, ) + self.shape[i],)\n",
    "    \n",
    "    def append(self, values):\n",
    "        with h5py.File(self.datapath, mode='a') as h5f:\n",
    "            for i in range(len(self.dataset)):\n",
    "                h5f[self.dataset[i]].resize((self.id[i] + values[i].shape[0], ) + self.shape[i])\n",
    "                h5f[self.dataset[i]][-values[i].shape[0]:] = values[i]\n",
    "                self.id[i] += values[i].shape[0]\n",
    "                h5f.flush()\n",
    "            \n",
    "    def load_dataset(self, hdf5_path):        \n",
    "            # Show keys            \n",
    "            N_db = 26\n",
    "            N_r = 4096\n",
    "            N_m = 24\n",
    "            dbs = np.arange(0,32,2)     \n",
    "            data_idxs_train = np.array([])\n",
    "            data_idxs_test = np.array([])\n",
    "            for i in np.arange(N_m):\n",
    "                for j in np.arange(10,10+len(dbs)):\n",
    "                    ids = i*N_r*N_db+j*N_r\n",
    "                    idx = np.arange(ids, ids+N_r)\n",
    "                    dataset = h5py.File(hdf5_path, \"r\")\n",
    "                    data = [dataset['X'][idx], dataset['Y'][idx]]\n",
    "#                     [print(item) for item in dataset.items()]                    \n",
    "                    self.append(data)\n",
    "\n",
    "# test\n",
    "hdf5_path = '/media/bognev/CE50072F50071DB9/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "hdf5_srore = HDF5Store('/tmp/GOLD_XYZ_OSC.0001_1024_truncated.hdf5',['X', 'Y'], shape=[(1024,2),(24,)], dtype=[np.float32, np.int32])\n",
    "hdf5_srore.load_dataset(hdf5_path)\n",
    "\n",
    "   \n",
    "!ls -l /tmp | grep 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -l /tmp\n",
    "import h5py\n",
    "with h5py.File('/tmp/GOLD_XYZ_OSC.0001_1024_truncated.hdf5', mode='r') as h5f:\n",
    "    [print(item) for item in h5f.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1024,2)\n",
    "print((None,)+ shape)\n",
    "print((0, ) + shape)\n",
    "print((0+4096, ) + shape)\n",
    "print((0+4096, ) + (24,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = np.arange(-20,32,2)   \n",
    "print(dbs[np.arange(10,10+13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = np.arange(0,28,2)     \n",
    "print(dbs)\n",
    "print(len(dbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "hdf5_path = '/media/bognev/CE50072F50071DB9/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "N_db = 26\n",
    "N_r = 4096\n",
    "N_m = 24\n",
    "dbs = np.arange(0,32,2)  \n",
    "data_idxs_train = np.array([])\n",
    "data_idxs_test = np.array([])\n",
    "for i in np.arange(N_m):\n",
    "    for j in np.arange(10,10+len(dbs)):\n",
    "        ids = i*N_r*N_db+j*N_r\n",
    "        idx = np.arange(ids, ids+N_r)\n",
    "        dataset = h5py.File(hdf5_path, \"r\")        \n",
    "#         print(dataset['X'][idx])        \n",
    "        print(dataset['Y'][idx[0]])\n",
    "        print(dataset['Z'][idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
